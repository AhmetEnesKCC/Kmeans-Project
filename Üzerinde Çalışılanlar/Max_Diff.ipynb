{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oN1C2SHPFP9Z"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as metric\n",
    "import math\n",
    "import sklearn.datasets as datasets\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "np.set_printoptions(suppress=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "z_u1x1FqFP9b"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "iris_data = np.array(iris.data)\n",
    "wine_data = np.array(wine.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FAoHD93hFP9c"
   },
   "outputs": [],
   "source": [
    "def calcSSE(data, centroids):\n",
    "    sum = 0\n",
    "    for i in data:\n",
    "        distance = math.inf\n",
    "        for k in centroids:\n",
    "            if euc(i, k) < distance:\n",
    "                distance = euc(i, k)\n",
    "        sum += distance ** 2\n",
    "\n",
    "    return sum / len(data)\n",
    "\n",
    "\n",
    "def euc(A, B):\n",
    "    # Call to scipy with vector parameters\n",
    "\n",
    "    return metric.euclidean(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "BpdxmueGFP9d"
   },
   "outputs": [],
   "source": [
    "def rand_cent(ds, k):\n",
    "    # Number of columns in dataset\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    # The centroids\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    # Create random centroids\n",
    "    for j in range(n):\n",
    "\n",
    "        min_j = min(ds[:, j])\n",
    "        range_j = float(max(ds[:, j]) - min_j)\n",
    "        centroids[:, j] = min_j + range_j * np.random.rand(k, 1)\n",
    "\n",
    "    # Return centroids as numpy array\n",
    "    return centroids\n",
    "def random_datapoints(ds,k):\n",
    "    index_list = random.sample(range(1,len(ds)),k)\n",
    "    centroids = ds[index_list]\n",
    "    return centroids\n",
    "def naive_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    ds.sort(axis=0)\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def mean_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.mean(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort(kind=\"mergesort\")]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def median_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.median(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def split_arr(ds, threshold, j):\n",
    "    if np.size(ds) == 0:\n",
    "        return None\n",
    "    min_val = ds[0, 0]\n",
    "\n",
    "    k = 0\n",
    "    for i in range(len(ds)):\n",
    "        if ds[k, 0]-min_val <= threshold:\n",
    "            # print(k)\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [j+k, ds[0:k, :]]\n",
    "\n",
    "def minmaxsharding(ds, k):\n",
    "\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "    # print(ds)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    # print(ds)\n",
    "    ds_range = np.max(ds[:, 0])-np.min(ds[:, 0])\n",
    "\n",
    "    threshold = ds_range/k\n",
    "    prev_arr = split_arr(ds, threshold, 0)\n",
    "\n",
    "    for j in range(k):\n",
    "        # print(prev_arr[1])\n",
    "        centroids[j, :] = np.sum(prev_arr[1][:, 1:], axis=0)/np.shape(prev_arr[1])[0]\n",
    "        # print(centroids)\n",
    "\n",
    "        prev_arr = split_arr(ds[prev_arr[0]:, :], threshold, prev_arr[0])\n",
    "        # print(\"done\")\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def l_inf(datas):\n",
    "    #datas bir numpy arrayi. Parametre olarak np array verilmeli veya alttaki yorum satıtındaki kod çalıştırılmalı:\n",
    "    #datas=datas.to_numpy() \n",
    "    num=len(datas[0])\n",
    "    for i in range(num):\n",
    "        m=max(datas[:,i])\n",
    "        datas[:,i]=datas[:,i]/m\n",
    "    return datas\n",
    "\n",
    "def norm_sharding(ds, k):\n",
    "    \n",
    "    n = np.shape(ds)[1]\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "    \n",
    "    normds = ds.copy()\n",
    "    normds = normalize(normds, axis=0, norm='max')\n",
    "    composite = np.sum(normds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "    ds.sort(axis=0)\n",
    "    \n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "St3ndO-OFP9f"
   },
   "outputs": [],
   "source": [
    "def kmeans(ds, k, cent_method):\n",
    "    global timer_start\n",
    "    global timer_end\n",
    "    global total_timer_end\n",
    "    return_object = {}\n",
    "    global cents\n",
    "    global sse\n",
    "    global iters\n",
    "    cents = []\n",
    "\n",
    "    if cent_method == \"random\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = rand_cent(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method ==\"random_datapoints\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = random_datapoints(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"naive\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = naive_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"mean\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = mean_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"median\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = median_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"minmax\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = minmaxsharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"norm_sharding\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = norm_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == 'near_sharding': \n",
    "        timer_start = time.perf_counter()\n",
    "        cents = near_sharding()\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == 'binary_method': \n",
    "        timer_start = time.perf_counter()\n",
    "        cents = binary_method(ds,k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"corner_method\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = corner_method(ds,k)\n",
    "        timer_end = time.perf_counter()\n",
    "    \n",
    "    km = KMeans(n_clusters=k, init=cents).fit(ds)\n",
    "    total_timer_end = time.perf_counter()\n",
    "    iters = km.n_iter_\n",
    "    cents = km.cluster_centers_\n",
    "    sse = km.inertia_\n",
    "    return_object['cents'] = cents\n",
    "    return_object['time'] = timer_end - timer_start\n",
    "    return_object['total-time'] = total_timer_end - timer_start\n",
    "    return_object['sse'] = sse / len(ds)\n",
    "    return_object['type'] = cent_method\n",
    "    return_object['iter'] = iters\n",
    "    return return_object\n",
    "\n",
    "\n",
    "def _get_mean(sums, step):\n",
    "    return sums/step\n",
    "\n",
    "def printResult(datas):\n",
    "    print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "        'Type', 'Time', \"SSE\", \"Total Time\", \"Iter\"))\n",
    "    print('-'*120)\n",
    "    for d in datas:\n",
    "        print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "            d['type'], d['time'], d['sse'], d['total-time'], d['iter']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "qsh8gdCbxFlz"
   },
   "outputs": [],
   "source": [
    "def binary_method(ds,k):\n",
    "  if k == 2:\n",
    "    centroids = np.array([ds.min(axis=0),ds.max(axis=0)])\n",
    "\n",
    "  else:\n",
    "    min_cent = ds.min(axis=0)\n",
    "\n",
    "    max_cent = ds.max(axis=0)\n",
    "    \n",
    "    centroids = np.array([min_cent,max_cent])\n",
    "    \n",
    "    diff = (max_cent-min_cent)/(k-1)\n",
    "    \n",
    "    for i in range(k-2):\n",
    "      centroids = np.append(centroids,[min_cent+(i+1)*diff],axis=0)\n",
    "      \n",
    "  return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ax27wgGbFP9i"
   },
   "outputs": [],
   "source": [
    "iris_ds = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UUydXkSWFP9k"
   },
   "outputs": [],
   "source": [
    "def max_diff(ds,k):\n",
    "    n = np.shape(ds)[1]\n",
    "    m = np.shape(ds)[0]\n",
    "    att_sums = sum(ds.T) #Transpose almazsan tüm satırların özelliklerini toplamak yerine \n",
    "                         #teker teker özelliklerin tüm örneklerdeki değerlerini topluyor.\n",
    "    att_sums = np.sort(att_sums)\n",
    "    diffs = np.zeros((len(att_sums)-1))\n",
    "    for idx in range(len(att_sums)-1):\n",
    "        diffs[idx] = att_sums[idx+1] - att_sums[idx]\n",
    "    \n",
    "    result = np.argsort(diffs)[-3:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "g_0e5TF-lXR4"
   },
   "outputs": [],
   "source": [
    "def corner_method(ds,k):\n",
    "    a=2\n",
    "    if k == 2:\n",
    "        centroids = np.array([ds.min(axis=0),ds.max(axis=0)])\n",
    "\n",
    "    else:\n",
    "        min_cent = ds.min(axis=0)\n",
    "        max_cent = ds.max(axis=0) \n",
    "        centroids = np.array([min_cent,max_cent])\n",
    "        num_col=ds.shape[1]\n",
    "        div=math.ceil(num_col/2) #başta yaklaşık yarı yarıya max/min yapacağımız için\n",
    "        num_cent=k-a # hepsi min ve max dışında bulunması gereken centroid sayısı\n",
    "        i=0\n",
    "        while i<num_cent:\n",
    "            while div>0:\n",
    "                if(i>=num_cent):\n",
    "                    break\n",
    "                num_comb=math.comb(num_col,div) #kombinasyon sayısı\n",
    "                cols=list(range(num_col)) # column sayısı kadar ardışık sayıdan oluşan array\n",
    "                combs = list(combinations(cols,div)) #cols un kombinasyonlarını tutan list\n",
    "                for j in range(num_comb):\n",
    "                    if(i>=num_cent):\n",
    "                        break\n",
    "                    maxes=ds[:,combs[j]].max(axis=0) #kombinasyondaki columnların max değerleri\n",
    "                    m=list(set(cols)-set(combs[j])) #kalan columnlar\n",
    "                    mins=ds[:,m].min(axis=0) #kalan columnların min değerleri\n",
    "                    new_cent=np.zeros(num_col) \n",
    "                    vals=np.concatenate((maxes,mins))\n",
    "                    pos=np.concatenate((combs[j],m))\n",
    "                    new_cent[pos]=vals\n",
    "                    #indexlerine göre max ve min değerlerini yerleştirip yeni centroidi belirledik.\n",
    "                    centroids = np.append(centroids,[new_cent],axis=0)\n",
    "                    i+=1\n",
    "                div-=1\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 3745,
     "status": "error",
     "timestamp": 1659518708948,
     "user": {
      "displayName": "Aysenur Atlac",
      "userId": "11191418536961012791"
     },
     "user_tz": -180
    },
    "id": "YpxFam2gFP9g",
    "outputId": "8f0dfe68-22ba-4301-fc65-82a778c064ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                           Time                           SSE                            Total Time                     Iter                          \n",
      "random                         0.0005559586666913674          0.5631622976979846             0.006922759333330457           8.43                          \n",
      "minmax                         0.0008019633333196907          0.5256762761743058             0.007901752666663622           4.0                           \n",
      "median                         0.0007959153333422364          0.5257044388398504             0.004763373000003715           3.0                           \n",
      "mean                           0.0005801566666635456          0.5257044388398504             0.004145356666660215           3.0                           \n",
      "naive                          0.0005194063333404604          0.5257044388398504             0.004007592666665308           3.0                           \n",
      "random_datapoints              7.049433331758337e-05          0.6242166289914087             0.004691694999992251           7.21                          \n",
      "norm_sharding                  0.0007445723333300218          0.5257044388398504             0.004289691000008133           3.0                           \n",
      "corner_method                  0.00025113100000301834         0.951690133477631              0.004129842666645042           5.0                           \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(iris.data)\n",
    "df = df.to_numpy()\n",
    "methods = ['random','minmax','median','mean','naive','random_datapoints','norm_sharding','corner_method']#near_sharding\n",
    "values = [[0 for j in range(5)] for i in range(len(methods))]\n",
    "repetition = 300\n",
    "for j in range(len(methods)):\n",
    "    for i in range(repetition):\n",
    "        values[j][0] = methods[j]\n",
    "        a = kmeans(df,3,methods[j])\n",
    "        values[j][1] += a[\"time\"]\n",
    "        values[j][2] += a[\"sse\"]\n",
    "        values[j][3] += a[\"total-time\"]\n",
    "        values[j][4] += a[\"iter\"]\n",
    "    for k in range(4):\n",
    "        values[j][k+1] = values[j][k+1]/repetition\n",
    "        \n",
    "print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "        'Type', 'Time', \"SSE\", \"Total Time\", \"Iter\"))\n",
    "for i in range(len(values)):\n",
    "    print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "            values[i][0], values[i][1], values[i][2], values[i][3], values[i][4]))\n",
    "    \n",
    "\n",
    "# printResult([kmeans(df, 3, 'random'), kmeans(df, 3, 'minmax'), \n",
    "#              kmeans(df, 3, 'median'), kmeans(df, 3, 'mean'), kmeans(df, 3, 'naive')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 6514,
     "status": "error",
     "timestamp": 1659518677353,
     "user": {
      "displayName": "Aysenur Atlac",
      "userId": "11191418536961012791"
     },
     "user_tz": -180
    },
    "id": "zAiRijiVGOAj",
    "outputId": "233ad495-930d-4640-e271-4253dfd65c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                           Time                           SSE                            Total Time                     Iter                          \n",
      "random                         0.0014981566666529033          0.15484252797562276            0.006815076999999595           9.396666666666667             \n",
      "minmax                         0.0008062919999989996          0.15348469815648305            0.00611294633333273            9.0                           \n",
      "median                         0.0009675486666492361          0.15358078306815307            0.006307566999980736           9.0                           \n",
      "mean                           0.0007836750000084672          0.15358078306815307            0.007394308666663771           9.0                           \n",
      "naive                          0.0007711486666721612          0.15358078306815307            0.007174573666667736           9.0                           \n",
      "random_datapoints              8.846266665689957e-05          0.153611356546831              0.006543797666655943           8.776666666666667             \n",
      "norm_sharding                  0.0012141626666774148          0.15358078306815307            0.008258089000011447           9.0                           \n",
      "binary_method                  0.00019790499999089662         0.1533992422049764             0.006790528000010454           10.0                          \n",
      "corner_method                  0.0006049346666713972          0.15358078306815307            0.008337971333329126           13.0                          \n"
     ]
    }
   ],
   "source": [
    "df=wine.data #np arrayi\n",
    "df=df.astype(float)\n",
    "df=l_inf(df)\n",
    "\n",
    "methods = ['random','minmax','median','mean','naive','random_datapoints','norm_sharding','binary_method','corner_method']\n",
    "values = [[0 for j in range(5)] for i in range(len(methods))]\n",
    "repetition = 300\n",
    "for j in range(len(methods)):\n",
    "    for i in range(repetition):\n",
    "        values[j][0] = methods[j]\n",
    "        a = kmeans(df,3,methods[j])\n",
    "        values[j][1] += a[\"time\"]\n",
    "        values[j][2] += a[\"sse\"]\n",
    "        values[j][3] += a[\"total-time\"]\n",
    "        values[j][4] += a[\"iter\"]\n",
    "    for k in range(4):\n",
    "        values[j][k+1] = values[j][k+1]/repetition\n",
    "        \n",
    "print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "        'Type', 'Time', \"SSE\", \"Total Time\", \"Iter\"))\n",
    "for i in range(len(values)):\n",
    "    print(\"{:<30} {:<30} {:<30} {:<30} {:<30}\".format(\n",
    "            values[i][0], values[i][1], values[i][2], values[i][3], values[i][4]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Max_Diff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbc1ed8668b58f0650135215bd5a4b0115d2d5c31696ff2caccb4edda4c2f1fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
