{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 Time                 SSE                  Total Time           Iter                \n",
      "-----------------------------------------------------------------------------------\n",
      "random               0.16681700001936406  119650390520146.98   0.4193995000096038   13                  \n",
      "minmax               0.2203942999476567   119650390520146.97   0.35520759993232787  4                   \n",
      "median               0.20629380003083497  119651632257641.83   0.360761099960655    4                   \n",
      "mean                 0.13847590005025268  119651632257641.83   0.2777388000395149   4                   \n",
      "naive                0.1662381999194622   119651632257641.83   0.34270079992711544  4                   \n"
     ]
    }
   ],
   "source": [
    "# %load Main_script2.py\n",
    "\"\"\"\n",
    "Created on Thu May  5 16:17:53 2022\n",
    "\n",
    "@author: salih\n",
    "\"\"\"\n",
    "\n",
    "from cmath import sqrt\n",
    "\n",
    "from matplotlib.pyplot import axis\n",
    "from sklearn.cluster import KMeans\n",
    "from elbow import calculateKWithElbow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as metric\n",
    "import math\n",
    "import sklearn.datasets as datasets\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "iris = pd.read_csv(\"3d_road.csv\")\n",
    "\n",
    "\n",
    "def calcSSE(data, centroids):\n",
    "    sum = 0\n",
    "    for i in data:\n",
    "        distance = math.inf\n",
    "        for k in centroids:\n",
    "            if euc(i, k) < distance:\n",
    "                distance = euc(i, k)\n",
    "        sum += distance ** 2\n",
    "\n",
    "    return sum / len(data)\n",
    "\n",
    "\n",
    "def euc(A, B):\n",
    "    # Call to scipy with vector parameters\n",
    "\n",
    "    return metric.euclidean(A, B)\n",
    "\n",
    "\n",
    "def rand_cent(ds, k):\n",
    "    # Number of columns in dataset\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    # The centroids\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    # Create random centroids\n",
    "    for j in range(n):\n",
    "\n",
    "        min_j = min(ds[:, j])\n",
    "        range_j = float(max(ds[:, j]) - min_j)\n",
    "        centroids[:, j] = min_j + range_j * np.random.rand(k, 1)\n",
    "\n",
    "    # Return centroids as numpy array\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def kmeans(ds, k, cent_method):\n",
    "    global timer_start\n",
    "    global timer_end\n",
    "    global total_timer_end\n",
    "    return_object = {}\n",
    "    global cents\n",
    "    global sse\n",
    "    global iters\n",
    "    cents = []\n",
    "\n",
    "    if cent_method == \"random\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = rand_cent(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"naive\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = naive_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"mean\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = mean_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"median\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = median_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"minmax\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = minmaxsharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    km = KMeans(n_clusters=k, init=cents).fit(ds)\n",
    "    total_timer_end = time.perf_counter()\n",
    "    iters = km.n_iter_\n",
    "    cents = km.cluster_centers_\n",
    "    sse = km.inertia_\n",
    "    return_object['cents'] = cents\n",
    "    return_object['time'] = timer_end - timer_start\n",
    "    return_object['total-time'] = total_timer_end - timer_start\n",
    "    return_object['sse'] = sse / len(ds)\n",
    "    return_object['type'] = cent_method\n",
    "    return_object['iter'] = iters\n",
    "    return return_object\n",
    "\n",
    "\n",
    "def _get_mean(sums, step):\n",
    "    return sums/step\n",
    "\n",
    "\n",
    "def naive_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    ds.sort(axis=0)\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def mean_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.mean(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort(kind=\"mergesort\")]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def median_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.median(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def minmaxsharding(ds, k):\n",
    "\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "    # print(ds)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    # print(ds)\n",
    "    ds_range = np.max(ds[:, 0])-np.min(ds[:, 0])\n",
    "\n",
    "    #threshold = math.ceil(ds_range/k)\n",
    "    threshold=ds_range/k\n",
    "    prev_arr = split_arr(ds, threshold, 0)\n",
    "\n",
    "    for j in range(k):\n",
    "        # print(prev_arr[1])\n",
    "        centroids[j, :] = np.sum(\n",
    "            prev_arr[1][:, 1:], axis=0)/np.shape(prev_arr[1])[0]\n",
    "        # print(centroids)\n",
    "\n",
    "        prev_arr = split_arr(ds[prev_arr[0]:, :], threshold, prev_arr[0])\n",
    "        # print(\"done\")\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def split_arr(ds, threshold, j):\n",
    "    if np.size(ds) == 0:\n",
    "        return None\n",
    "    min_val = ds[0, 0]\n",
    "\n",
    "    k = 0\n",
    "    for i in range(len(ds)):\n",
    "        if ds[k, 0]-min_val <= threshold:\n",
    "            # print(k)\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [j+k, ds[0:k, :]]\n",
    "\n",
    "\n",
    "def printResult(datas):\n",
    "    print(\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\n",
    "        'Type', 'Time', \"SSE\", \"Total Time\", \"Iter\"))\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    for d in datas:\n",
    "        print(\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\n",
    "            d['type'], d['time'], d['sse'], d['total-time'], d['iter']))\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(iris.data)\n",
    "df = iris.iloc[:, 0:4]\n",
    "\n",
    "#df=iris\n",
    "df = df.to_numpy()\n",
    "printResult([kmeans(df, 3, 'random'), kmeans(\n",
    "    df, 3, 'minmax'), kmeans(df, 3, 'median'), kmeans(df, 3, 'mean'), kmeans(df, 3, 'naive')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.astype(float)\n",
    "num=len(df[0])\n",
    "for i in range(num):\n",
    "    m=max(df[:,i])\n",
    "    #print(m)\n",
    "    df[:,i]=df[:,i]/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 Time                 SSE                  Total Time           Iter                \n",
      "-----------------------------------------------------------------------------------\n",
      "random               0.22859229997266084  0.026732051420327217 0.40745209995657206  5                   \n",
      "minmax               0.37134660000447184  0.026995805956841885 0.6224225999321789   10                  \n",
      "median               0.26447330007795244  0.02673253174000223  0.5288417000556365   17                  \n",
      "mean                 0.21016679995227605  0.02673253174000223  0.4935232999268919   17                  \n",
      "naive                0.2016439000144601   0.02673253174000223  0.46108350006397814  17                  \n"
     ]
    }
   ],
   "source": [
    "printResult([kmeans(df, 3, 'random'), kmeans(\n",
    "    df, 3, 'minmax'), kmeans(df, 3, 'median'), kmeans(df, 3, 'mean'), kmeans(df, 3, 'naive')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
