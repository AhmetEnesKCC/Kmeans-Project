{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28a8cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 Time                 SSE                  Total Time           Iter                \n",
      "-----------------------------------------------------------------------------------\n",
      "random               0.0001140000531449914 700.346521885522     0.002476300112903118 6                   \n",
      "minmax               0.000305499997921288 661.2112190963343    0.0031609999714419246 4                   \n",
      "median               0.00043810007628053427 225.4453264234756    0.00295290001668036  4                   \n",
      "mean                 0.00033460010308772326 225.4453264234756    0.002657800097949803 4                   \n",
      "naive                0.0003085000207647681 225.4453264234756    0.002179499948397279 4                   \n"
     ]
    }
   ],
   "source": [
    "# %load Main_script2.py\n",
    "\"\"\"\n",
    "Created on Thu May  5 16:17:53 2022\n",
    "\n",
    "@author: salih\n",
    "\"\"\"\n",
    "\n",
    "from cmath import sqrt\n",
    "\n",
    "from matplotlib.pyplot import axis\n",
    "from sklearn.cluster import KMeans\n",
    "from elbow import calculateKWithElbow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as metric\n",
    "import math\n",
    "import sklearn.datasets as datasets\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "iris = pd.read_csv(\"ruspini.csv\")\n",
    "\n",
    "\n",
    "def calcSSE(data, centroids):\n",
    "    sum = 0\n",
    "    for i in data:\n",
    "        distance = math.inf\n",
    "        for k in centroids:\n",
    "            if euc(i, k) < distance:\n",
    "                distance = euc(i, k)\n",
    "        sum += distance ** 2\n",
    "\n",
    "    return sum / len(data)\n",
    "\n",
    "\n",
    "def euc(A, B):\n",
    "    # Call to scipy with vector parameters\n",
    "\n",
    "    return metric.euclidean(A, B)\n",
    "\n",
    "\n",
    "def rand_cent(ds, k):\n",
    "    # Number of columns in dataset\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    # The centroids\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    # Create random centroids\n",
    "    for j in range(n):\n",
    "\n",
    "        min_j = min(ds[:, j])\n",
    "        range_j = float(max(ds[:, j]) - min_j)\n",
    "        centroids[:, j] = min_j + range_j * np.random.rand(k, 1)\n",
    "\n",
    "    # Return centroids as numpy array\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def kmeans(ds, k, cent_method):\n",
    "    global timer_start\n",
    "    global timer_end\n",
    "    global total_timer_end\n",
    "    return_object = {}\n",
    "    global cents\n",
    "    global sse\n",
    "    global iters\n",
    "    cents = []\n",
    "\n",
    "    if cent_method == \"random\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = rand_cent(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"naive\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = naive_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"mean\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = mean_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"median\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = median_sharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    elif cent_method == \"minmax\":\n",
    "        timer_start = time.perf_counter()\n",
    "        cents = minmaxsharding(ds, k)\n",
    "        timer_end = time.perf_counter()\n",
    "    km = KMeans(n_clusters=k, init=cents).fit(ds)\n",
    "    total_timer_end = time.perf_counter()\n",
    "    iters = km.n_iter_\n",
    "    cents = km.cluster_centers_\n",
    "    sse = km.inertia_\n",
    "    return_object['cents'] = cents\n",
    "    return_object['time'] = timer_end - timer_start\n",
    "    return_object['total-time'] = total_timer_end - timer_start\n",
    "    return_object['sse'] = sse / len(ds)\n",
    "    return_object['type'] = cent_method\n",
    "    return_object['iter'] = iters\n",
    "    return return_object\n",
    "\n",
    "\n",
    "def _get_mean(sums, step):\n",
    "    return sums/step\n",
    "\n",
    "\n",
    "def naive_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    ds.sort(axis=0)\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def mean_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.mean(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort(kind=\"mergesort\")]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def median_sharding(ds, k):\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    m = np.shape(ds)[0]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.median(ds, axis=1)\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    step = math.floor(m/k)\n",
    "\n",
    "    vfunc = np.vectorize(_get_mean)\n",
    "\n",
    "    for j in range(k):\n",
    "        if j == k-1:\n",
    "            centroids[j:] = vfunc(np.sum(ds[j*step:, 1:], axis=0), step)\n",
    "        else:\n",
    "            centroids[j:] = vfunc(\n",
    "                np.sum(ds[j*step:(j+1)*step, 1:], axis=0), step)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def minmaxsharding(ds, k):\n",
    "\n",
    "    n = np.shape(ds)[1]\n",
    "\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "\n",
    "    composite = np.sum(ds, axis=1)\n",
    "\n",
    "    composite = np.reshape(composite, (len(ds), 1))\n",
    "\n",
    "    ds = np.append(composite, ds, axis=1)\n",
    "    # print(ds)\n",
    "\n",
    "    # ds = ds[ds[:, 0].argsort()]\n",
    "    ds.sort(axis=0)\n",
    "\n",
    "    # print(ds)\n",
    "    ds_range = np.max(ds[:, 0])-np.min(ds[:, 0])\n",
    "\n",
    "    #threshold = math.ceil(ds_range/k)\n",
    "    threshold=ds_range/k\n",
    "    prev_arr = split_arr(ds, threshold, 0)\n",
    "\n",
    "    for j in range(k):\n",
    "        # print(prev_arr[1])\n",
    "        centroids[j, :] = np.sum(\n",
    "            prev_arr[1][:, 1:], axis=0)/np.shape(prev_arr[1])[0]\n",
    "        # print(centroids)\n",
    "\n",
    "        prev_arr = split_arr(ds[prev_arr[0]:, :], threshold, prev_arr[0])\n",
    "        # print(\"done\")\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def split_arr(ds, threshold, j):\n",
    "    if np.size(ds) == 0:\n",
    "        return None\n",
    "    min_val = ds[0, 0]\n",
    "\n",
    "    k = 0\n",
    "    for i in range(len(ds)):\n",
    "        if ds[k, 0]-min_val <= threshold:\n",
    "            # print(k)\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [j+k, ds[0:k, :]]\n",
    "\n",
    "\n",
    "def printResult(datas):\n",
    "    print(\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\n",
    "        'Type', 'Time', \"SSE\", \"Total Time\", \"Iter\"))\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    for d in datas:\n",
    "        print(\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\n",
    "            d['type'], d['time'], d['sse'], d['total-time'], d['iter']))\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(iris.data) yapmamıza gerek yok çünkü iris = pd.read_csv(\"ruspini.csv\") deki iris zaten df\n",
    "df = iris.iloc[:, [1,2]]\n",
    "#df=iris\n",
    "df = df.to_numpy()\n",
    "printResult([kmeans(df, 4, 'random'), kmeans(\n",
    "    df, 4, 'minmax'), kmeans(df, 4, 'median'), kmeans(df, 4, 'mean'), kmeans(df, 4, 'naive')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1562477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \t \t SSE \t \t\t\t iter\n",
      "random \t\t 350.3150344106723 \t \t 4.29\n",
      "minmax \t\t 661.2112190963325 \t \t 4.0\n",
      "median \t\t 225.44532642347593 \t \t 4.0\n",
      "mean \t\t 225.44532642347593 \t \t 4.0\n",
      "naive \t\t 225.44532642347593 \t \t 4.0\n"
     ]
    }
   ],
   "source": [
    "names=['random','minmax','median','mean','naive']\n",
    "topl=[0]*5\n",
    "topl2=[0]*5\n",
    "j=0\n",
    "for i in range (100):\n",
    "    a=kmeans(df, 4, 'random')\n",
    "    topl[j]=topl[j]+a['sse']\n",
    "    topl2[j]=topl2[j]+a['iter']\n",
    "    a=kmeans(df, 4, 'minmax')\n",
    "    topl[j+1]=topl[j+1]+a['sse']\n",
    "    topl2[j+1]=topl2[j+1]+a['iter']\n",
    "    a=kmeans(df, 4, 'median')\n",
    "    topl[j+2]=topl[j+2]+a['sse']\n",
    "    topl2[j+2]=topl2[j+2]+a['iter']\n",
    "    a=kmeans(df, 4, 'mean')\n",
    "    topl[j+3]=topl[j+3]+a['sse']\n",
    "    topl2[j+3]=topl2[j+3]+a['iter']\n",
    "    a=kmeans(df, 4, 'naive')\n",
    "    topl[j+4]=topl[j+4]+a['sse']\n",
    "    topl2[j+4]=topl2[j+4]+a['iter']    \n",
    "avrg=[0]*5\n",
    "avrg2=[0]*5\n",
    "print(\"Type \\t \\t SSE \\t \\t\\t\\t iter\")\n",
    "for k in range (5):\n",
    "    avrg[k]=topl[k]/100\n",
    "    avrg2[k]=topl2[k]/100\n",
    "    print(names[k],\"\\t\\t\",avrg[k],\"\\t \\t\",avrg2[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9c9da9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.0\n",
      "156.0\n"
     ]
    }
   ],
   "source": [
    "df = iris.iloc[:, [1,2]]\n",
    "#df=iris\n",
    "df = df.to_numpy()\n",
    "df=df.astype(float)\n",
    "num=len(df[0])\n",
    "for i in range(num):\n",
    "    m=max(df[:,i])\n",
    "    print(m)\n",
    "    df[:,i]=df[:,i]/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85771cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 Time                 SSE                  Total Time           Iter                \n",
      "-----------------------------------------------------------------------------------\n",
      "random               0.000206699944101274 0.012118143593700278 0.0034691999899223447 4                   \n",
      "minmax               0.000355200027115643 0.03829836015277137  0.0029597999528050423 3                   \n",
      "median               0.0005777999758720398 0.012118143593700278 0.0032310999231413007 5                   \n",
      "mean                 0.0003450000658631325 0.012118143593700278 0.0024060000432655215 5                   \n",
      "naive                0.00030610000248998404 0.012118143593700278 0.002498700050637126 5                   \n"
     ]
    }
   ],
   "source": [
    "printResult([kmeans(df, 4, 'random'), kmeans(\n",
    "    df, 4, 'minmax'), kmeans(df, 4, 'median'), kmeans(df, 4, 'mean'), kmeans(df, 4, 'naive')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "00afaba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    " a=math.ceil(0.017)\n",
    " print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5d0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
